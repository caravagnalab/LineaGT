run_selection = function(dataset, lineages, k_min=5, k_max=25, n_runs=3,
                         columns=list(), IS_values=list(),
                         min_cov=50, min_ccf=0.05, k_interval=c(5,25), metric="calinski_harabasz_score",
                         steps=500, lr=0.005, covariance="diag",
                         filename="", random_state=25) {
  ic = data.frame(matrix(nrow=0, ncol=4)); colnames(ic) = c("BIC", "AIC", "ICL", "NLL")
  losses = data.frame(matrix(nrow=0, ncol=steps)); colnames(losses) = paste("iter_", 1:steps, sep="")
  grads = data.frame(matrix(nrow=0, ncol=steps)); colnames(grads) = paste("iter_", 1:steps, sep="")

  for (k in as.integer(k_min):as.integer(k_max)) {
    obj = lineaGT::mixture_model(k, dataset, lineages=lineages, columns=columns, IS_values=IS_values)
    obj = lineaGT::filter_dataset(obj, min_cov=min_cov, min_ccf=min_ccf, k_interval=k_interval,
                                  metric=metric, random_state=random_state)

    IS_k = obj$dataframe$IS
    columns_k = obj$dimensions
    df = obj$dataframe

    for (run in 1:n_runs) {
      obj_k = selection_util(run, k, df, lineages, columns_k, IS_k, steps, covariance, lr, random_state)

      kk = obj_k$K
      n_iter = obj_k$n_iter
      ic[paste(kk, run,sep=":"),] = list("BIC"=obj_k$BIC, "AIC"=obj_k$AIC, "ICL"=obj_k$ICL, "NLL"=obj_k$NLL)
      losses[paste(kk, run, sep=":"),1:n_iter] = obj_k$losses
      grads[paste(kk, run, "mean", sep=":"), 1:n_iter] = obj_k$mean_grad
      grads[paste(kk, run, "sigma", sep=":"), 1:n_iter] = obj_k$sigma_grad
      grads[paste(kk, run, "weights", sep=":"), 1:n_iter] = obj_k$weights_grad
    }
    gc()
  }

  selection = list("ic"=ic, "losses"=losses, "grads"=grads)

  if (filename != "") saveRDS(object=selection, file=filename)
  return(selection)
}


selection_util = function(run, k, df, lineages, columns_k, IS_k, steps=500, covariance="diag", lr=0.001, random_state=25) {
  print(paste("RUN", run, "- K =", k))
  obj_k = lineaGT::mixture_model(k, df, lineages=lineages, columns=columns_k, IS_values=IS_k)
  obj_k = lineaGT::run_inference(obj_k, steps=as.integer(steps), covariance=covariance,
                                 lr=as.numeric(lr), random_state=random_state)
  obj_k = lineaGT::classifier(obj_k)

  obj_k$BIC = obj_k$py_model$compute_ic(method="BIC")$numpy()
  obj_k$AIC = obj_k$py_model$compute_ic(method="AIC")$numpy()
  obj_k$ICL = obj_k$py_model$compute_ic(method="ICL")$numpy()
  obj_k$NLL = obj_k$py_model$nll$numpy()

  obj_k$losses = obj_k$py_model$losses_grad_train$losses
  obj_k$mean_grad = obj_k$py_model$losses_grad_train$gradients$mean_param
  obj_k$sigma_grad = obj_k$py_model$losses_grad_train$gradients$sigma_vector_param
  obj_k$weights_grad = obj_k$py_model$losses_grad_train$gradients$weights_param

  obj_k$n_iter = obj_k$py_model$losses_grad_train$losses %>% length

  return(obj_k)
}
